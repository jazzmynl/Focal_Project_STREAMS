---
title: "Water Quality Cleaning"
author: "Sully Riley"
format: html
editor: visual
---

### Import Libraries

```{r}
library(tidyverse)
library(assertthat)
```

## Import Data

```{r}
RAW_DATA_FILE_PATH = "water-quality-raw/"
SHOULD_RUN_ASSERTIONS = FALSE
SHOULD_FILTER_ALL_WQ = F

assert = function(assertion, msg = msg) {
  if(SHOULD_RUN_ASSERTIONS) {
    assert_that(
      assertion,
      msg = msg
    )
  }
}
```

### Water Stations

```{r}
water_stations_raw = readxl::read_excel(paste(RAW_DATA_FILE_PATH, 'WaterStationSites-2-26-24.xlsx', sep = ''))

water_stations = water_stations_raw |> 
  rename(
    station_code = `StationCode`,
    fire_distance = `FireDistance`,
    latitude = `latitude`,
    longitude = `longitude`,
    elevation = `Elevation`,
    ecoregion_code = `EcoregionCode`,
    ecoregion = `Ecoregion`,
    fire_year = `FIRE_YEAR`,
    fire_name = `FIRE_NAME`,
    fire_start = `FIRE_START`,
    fire_contained = `FIRE_CONTAINED`,
    gis_acres = `GIS_ACRES`,
    prox_id = `Prox_ID`,
    fire_history_type = `Type`,
    water_station_id = `WaterStation_ID`,
) |> 
  mutate(
    fire_start = ymd(fire_start),
    fire_contained = ymd(fire_contained)
  ) 
```

### Water Quality

```{r}
if (SHOULD_FILTER_ALL_WQ) {
  all_water_quality_raw <- read_csv(paste(RAW_DATA_FILE_PATH, "AllWQ.csv", sep = ''))

  water_quality_for_stations = all_water_quality_raw |> 
    filter(all_water_quality_raw$StationCode %in% water_stations$station_code)

  write_csv(water_quality_for_stations, paste(RAW_DATA_FILE_PATH, "wq-for-stations.csv", sep = ''))
}

water_quality_raw = read_csv(paste(RAW_DATA_FILE_PATH, "wq-for-stations.csv", sep = ''))

water_quality = water_quality_raw |> rename(
  station_code = `StationCode`,
  collection_depth = `CollectionDepth`,  
  unit_collection_depth = `UnitCollectionDepth`, 
  analyte = `Analyte`,             
  unit = `Unit`,           
  result = `Result`,        
  latitude = `latitude`,           
  longitude = `longitude`,   
  position_water_column = `PositionWaterColumn`,
  huc12_name = `Huc12_name`,  
  huc12_number = `Huc12_number`,  
  sample_date = `SampleDate`, 
  collection_time = `CollectionTime`
  ) |>  
  mutate(sample_date_time = mdy_hms(sample_date))

hour(water_quality$sample_date_time) = hour(mdy_hms(water_quality$collection_time))
minute(water_quality$sample_date_time) = minute(mdy_hms(water_quality$collection_time))
second(water_quality$sample_date_time) = second(mdy_hms(water_quality$collection_time))

water_quality = water_quality |> 
  select(-c(sample_date, collection_time))

```

### CRAM Sites / CRAM Measurements

These are stored in a single table

```{r}
cram_measurements_raw = readxl::read_excel(paste(RAW_DATA_FILE_PATH, "FinalizedCramSites-2-26-24.xlsx", sep = '')) 

cram_measurements = cram_measurements_raw |> 
  rename(
    ecram_id                = `ecramid`,
    visit_date              = `visitdate`,
    fire_history_type       = `Fire/Control`,
    time_relative_to_fire   = `Pre/Post_Fire`,
    group_id                = `Group_ID`,
    pair_id                 = `Pair_ID`,
    index_score             = `indexscore`,
    buffer_lan              = `bufferlan`,
    hydrology               = `hydrology`,
    physical                = `physical`,
    biotic_str              = `biotic_str`,
    year                    = `YEAR_`,
    fire_name               = `FIRE_NAME`,
    alarm_date              = `ALARM_DATE`,
    cont_date               = `CONT_DATE`,
    us_l4code               = `US_L4CODE`,
    us_l4name               = `US_L4NAME`,
    nearest_fire            = `NearestFire`,
    near_fid                = `NEAR_FID`,
    site_id                 = `SITE_ID`,
    prox_id                 = `PROX_ID`,
    shape_length            = `SHAPE_Length`,
    shape_area              = `SHAPE_Area`,
    mountain_range          = `MountainRange`,
    time_interval_elevation = `TimeInterval/Elevtation`,
  ) |> 

  # format date
  mutate(
    visit_date = ymd(visit_date),
    alarm_date = ymd(alarm_date),
    cont_date = ymd(cont_date)
    
  ) 
```

## SKIP

### OLD

#### Group measurements by nearest timeframe

Could be week, month, season, year

```{r}
# water_quality = water_quality #|> 
#   #mutate(Timeframe = floor_date(SampleDate, 'year'))
# 
# water_quality

```

Amy's suggestions

```{r}
# water_quality |> 
#   mutate(Year = year(mdy_hms(SampleDate))) |> 
#   group_by(StationCode, Year) |> 
#   count(Analyte) |> 
#   arrange(n)
#
# water_quality |> 
#   select(Analyte, StationCode) |> 
#   distinct() |> 
#   group_by(Analyte) |> 
#   count() |> 
#   arrange(-n)

```

### Select StationsWater Stations in Fire Range

```{r}
# WaterStationFireSite_Raw = readxl::read_excel('water-quality-raw/WaterStationFireSites.xlsx')
#
# # don't actually have a good one here - need from garrett 
# water_stationsCRAMMap = WaterStationFireSite_Raw |> 
#   select(c(StationCode, visitdate, Pair_ID)) |> 
#   filter(!(is.na(visitdate) & is.na(Pair_ID))) |> 
#   mutate(Pair_ID = parse_number(Pair_ID) |> paste('a', sep = '')) |> 
#   mutate(unique_visit_date_pair_id = paste(visitdate, Pair_ID, sep = '-'))
# # this isn't working bc the pairIds are duplicated
# x = left_join(cram_measurements, water_stationsToCRAM)
#
# water_stations.Fire = WaterStationFireSite_Raw |> 
#   select(-c(visitdate, Pair_ID)) |> 
#   unique()
```

#### About this data:

|     | Column Name      | Type        | Notes                                                   |
|------------|------------|------------|------------------------------------|
| 1   | `StationCode`    | chr         |                                                         |
| 2   | `FireDistance`   | dbl         |                                                         |
| 3   | `latitude`       | dbl         |                                                         |
| 4   | `longitude`      | dbl         |                                                         |
| 5   | `Elevation`      | dbl         |                                                         |
| 6   | `EcoregionCode`  | chr         |                                                         |
| 7   | `Ecoregion`      | chr         |                                                         |
| 8   | `FIRE_YEAR`      | dbl         |                                                         |
| 9   | `FIRE_NAME`      | chr         |                                                         |
| 10  | `FIRE_START`     | S3: POSIXct |                                                         |
| 11  | `FIRE_CONTAINED` | S3: POSIXct |                                                         |
| 12  | `GIS_ACRES`      | dbl         |                                                         |
| 13  | `vistdate`       | S3: POSIXct | CRAM visit date?                                        |
| 14  | `Pair_ID`        | chr         | If present, has matching CRAM site (within x distance?) |

#### Questions about this data

-   i noticed that the control set includes the fire station codes (though doesn’t include some of the CRAM site metadata) - is that intentional or should I just filter those out?

-   I noticed that for the water stations within the fire, you matched it up to the cram site if applicable - should we do the same for the control stations, or were there none?

-   a question about the pair_Id in the water stations for fire - i think some of them match the control CRAM data if I’m not mistaken? but I think they should all be fire, right?

```{r}

```

#### Questions about this data

-   What is Prox_ID?

## Confidence Checks

```{r}

# 
# # All Water Stations should have a unique code.
# validate_that(
#   water_stations$StationCode |> unique() |> length() == water_stations$StationCode |> length(),
#   msg = 'All Water Stations do not have a unique code'
#   )
# 
# # maybe not needed
# validate_that(
#   water_stations.Fire |>
#     filter(StationCode %in% water_stations.Control$StationCode) |>
#     length()
#   == 0,
#   msg = "Water Stations in control and water stations in fire are not exclusive."
# )
# 
# validate_that(
#   FALSE,
#   msg = "There should be one row per water station in the mapping"
# )

```

## Clean Data

1.  Get only WQ data for applicable Water Stations

```{r}
water_quality = water_quality |> filter(station_code %in% water_stations$station_code)
```

2.  Set target date for water station measurements

```{r}
assert(
  water_stations |> filter(is.na(fire_name)) |> nrow() == 0,
  msg = 'All Water Stations should have an associated fire'
  )

target_date_distance = dmonths(6)

water_station_observations = water_stations |>
  pivot_longer(
    cols = c(fire_start, fire_contained),
    names_to = "fire_date_type",
    values_to = "fire_date"
  ) |> 
  mutate(
    target_date_type = case_when(
      fire_date_type == 'fire_start' ~ "pre",
      fire_date_type == 'fire_contained' ~ "post",
    )
  ) |> 
  # determining target date in separate mutation in case this changes
  mutate(
    target_date = case_when(
      target_date_type == "pre" ~ as.Date(fire_date - target_date_distance),
      target_date_type == "post" ~ as.Date(fire_date + target_date_distance)
    )
  )
```

3.  Normalize analytes

```{r}

## clean up units per analyte 

analytes = water_quality |> 
  select(c(analyte, unit)) |>
  group_by(analyte) |> 
  reframe(
    unit = unique(unit)
  ) 

duplicate_analytes = analytes |> 
  group_by(analyte) |> 
  filter(n() > 1)

assert(
  duplicate_analytes |> nrow() == 0,
  msg = "Analytes should not have more than one unit"
)

analytes
```

4.  Determine fire and target date for water quality data

```{r}

assert(
  water_stations$station_code |> length() == water_stations$station_code |> unique() |> length(),
  msg = "water stations should have unique codes"
)

assert(
  water_station_observations$station_code |> length() == water_stations$station_code |> length() * 2,
  msg = "there should be twice as many observations as stations"
)

assert(
  water_quality |> filter(
  !(water_quality$station_code %in% water_stations$station_code)
) |> nrow() == 0 &
water_stations |> filter(
  !(water_stations$station_code %in% water_quality$station_code)
) |> nrow() == 0
, msg = "There should be no station codes that are only in one set"
)

TARGET_DATE_BUFFER = dyears(5)

valid_water_quality = water_station_observations |> 
  left_join(
    water_quality |> 
      select(-c(latitude, longitude)), 
    by = join_by(station_code), 
    relationship = "many-to-many"
  ) |> 
  filter(
    fire_date_type == "fire_start" & sample_date_time < fire_date |
    fire_date_type == "fire_contained" & sample_date_time > fire_date) |> 
  mutate(
    distance_from_target_date = abs(sample_date_time - as_datetime(target_date))
  ) |> 
  filter(distance_from_target_date < TARGET_DATE_BUFFER) |> 
  group_by(station_code, target_date_type, analyte) |>
  filter(
    distance_from_target_date == min(distance_from_target_date)
  )

 # sometimes there are multiple readings for the same time, date, and analyte
 # sometimes there different readings at surface vs subsurface
 valid_water_quality |>
       select(colnames(water_quality)) |> 
  filter(n() > 1) |> 
  arrange(.by_group = T)

 # assert there is one per group
 assert(
   valid_water_quality |>
   filter(n() > 1) |> nrow() == 0,
   msg = "There should be one analyte per group"
 )
  
# for now just take the mean and investigate later
 mean_water_quality = valid_water_quality |> 
   reframe(
     result = mean(result)
   )
 
 # need to bring back the unit (fix this assertion)
 assert(
   mean_water_quality$unit |> unique() |> length() > 0
 )
 
 # strategy for analytes 
 STRATEGY = "post-only"
 if (STRATEGY == "pre-post-pairs") {
    valid_stations_with_analytes = mean_water_quality |> 
       group_by(station_code, analyte) |> 
       reframe(
         timeframes = unique(target_date_type) |> length()
       ) |> 
       filter(timeframes > 1) |> 
       select(station_code, analyte)
              
    optimized_water_quality = left_join(valid_stations_with_analytes, mean_water_quality, by = join_by(station_code, analyte))
        
    assert(
        filter(
          optimized_water_quality,
          target_date_type == "pre"
        ) |> 
        nrow() == filter(
          optimized_water_quality,
          target_date_type == "post"
        ) |> nrow(),
      msg = "Should have same number pre and post"
    )
 } else if (STRATEGY == "post-only") {
   valid_stations_with_analytes = mean_water_quality |> 
     filter(target_date_type == "post") |> 
     select(station_code, analyte, target_date_type)
   
    optimized_water_quality = left_join(valid_stations_with_analytes, mean_water_quality, by = join_by(station_code, analyte, target_date_type))
    
    assert(
      optimized_water_quality |> 
        filter(
          target_date_type == "pre"
        ) |> 
        nrow() == 0,
      msg = "Should exclude pre"
    )
 }  

 
 assert(
   (sum(is.na(optimized_water_quality))) == 0,
   msg = "Should be no NAs"
 )
 
 assert(sum(is.na( (optimized_water_quality |> pivot_wider(
   id_cols = c(station_code, analyte),
   names_from = target_date_type,
   values_from = result
 )))) == 0,
 msg = "There should be no missing results"
 )

```

## Select Analytes

```{r}

analytes_count = optimized_water_quality |>
  group_by(station_code) |> 
  count(analyte) 

analytes_count_wide = analytes_count |>
  pivot_wider(
    id_cols = c(station_code),
    names_from = analyte,
    values_from = n
  )
analytes_count_matrix = data.matrix(analytes_count_wide[,2:length(analytes_count_wide)])

rownames(analytes_count_matrix) = analytes_count_wide$station_code

analytes_count_matrix[is.na(analytes_count_matrix)] = 0
analytes_count_matrix[analytes_count_matrix > 0] = 1

analytes_count_matrix |> View()

# How many stations-timeframes have this analyte? 
most_measured_analyte_num_stations = max(colSums(analytes_count_matrix))
most_measured_station_num_analytes = max(rowSums(analytes_count_matrix))


minNumStationsWithAnalyte = min(colSums(analytes_count_matrix))
minNumAnalytesAtStation = min(rowSums(analytes_count_matrix)) 

while(0 %in% analytes_count_matrix) {
 if ( minNumStationsWithAnalyte > 0 & 
  minNumAnalytesAtStation > 0 & minNumStationsWithAnalyte <= minNumAnalytesAtStation) {
  colsToKeep = colSums(analytes_count_matrix) != minNumStationsWithAnalyte
  
  print(paste('Dropping', length(colsToKeep[!colsToKeep]), 'of', length(colsToKeep), 'analytes:')) 
  print(names(colsToKeep)[!colsToKeep])

  analytes_count_matrix = analytes_count_matrix[,colsToKeep] 
} else {
  rowsToKeep = rowSums(analytes_count_matrix) != minNumAnalytesAtStation
  
  print(paste('Dropping', length(rowsToKeep[!rowsToKeep]), 'of', length(rowsToKeep), 'stations:')) 
  print(names(rowsToKeep)[!rowsToKeep])

  analytes_count_matrix = analytes_count_matrix[rowsToKeep,]
}

    
  minNumStationsWithAnalyte = min(colSums(analytes_count_matrix))
minNumAnalytesAtStation = min(rowSums(analytes_count_matrix)) 
}

```

### 

```{r}
water_station_observations_refined = 
  as.data.frame(analytes_count_matrix) |>
  mutate(station_code = rownames(analytes_count_matrix)) |> 
  pivot_longer(cols = !station_code, names_to = "analyte") |> 
  left_join(optimized_water_quality, by = join_by(station_code, analyte)) |> 
  left_join(water_stations)

water_station_observations_refined |> filter(is.na(result))

optimized_analytes_results = water_station_observations_refined |> pivot_wider(
    id_cols = c(station_code, target_date_type, fire_history_type),
    names_from = analyte,
    values_from = result
) 

analytes_results_matrix = data.matrix(optimized_analytes_results[,3:length(optimized_analytes_results)])
rownames(analytes_results_matrix) = paste(optimized_analytes_results$station_code, optimized_analytes_results$target_date_type,
optimized_analytes_results$fire_history_type,
sep = "::")

assert(
  sum(is.na(analytes_results_matrix)) == 0,
  msg = "there should be no NAs in the results matrix"
)
```

## PCA

```{r}
library(vegan)
library(factoextra)


# Way to do it so you can get eigenvalues/goodness of fit
results_distance <- vegdist(analytes_results_matrix, method = "bray")

results_pca = prcomp(results_distance, scale = TRUE)

fviz_eig(results_pca)

fviz_pca_ind(results_pca)

fviz_pca_ind(
  results_pca, 
  axes = c(1, 2), # change which PCA axes you're viewing here
             
  col.ind = "cos2", # Color by the quality of representation
             
  gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             
  repel = TRUE     # Avoid text overlapping
)
```
