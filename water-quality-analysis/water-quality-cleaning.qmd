---
title: "Water Quality Cleaning"
author: "Sully Riley"
format: html
editor: visual
---

### Import Libraries

```{r}
library(tidyverse)
library(assertthat)

source("utils.R")
```

## Import Data

```{r}
RAW_DATA_FILE_PATH = "water-quality-raw/"
SHOULD_RUN_ASSERTIONS = T
SHOULD_FILTER_ALL_WQ = T

assert = function(assertion, msg = msg) {
  if(SHOULD_RUN_ASSERTIONS) {
    assert_that(
      assertion,
      msg = msg
    )
  }
}
```

### Water Stations

```{r}
water_stations_raw = readxl::read_excel(paste(RAW_DATA_FILE_PATH, 'WaterStationSites-3-5-24.xlsx', sep = ''))

water_stations = water_stations_raw |> 
  rename(
    station_code = `StationCode`, # required for analysis
    fire_start = `ALARM_DATE`, # required for analysis
    fire_contained = `CONT_DATE`, # required for analysis
    fire_name = `FIRE_NAME`
    
    # fire_distance = `FireDistance`,
    # latitude = `latitude`,
    # longitude = `longitude`,
    # elevation = `Elevation`,
    # ecoregion_code = `EcoregionCode`,
    # ecoregion = `Ecoregion`,
    # fire_year = `FIRE_YEAR`,
    # fire_name = `FIRE_NAME`,
    # fire_start = `FIRE_START`,
    # fire_contained = `FIRE_CONTAINED`,
    # gis_acres = `GIS_ACRES`,
    # prox_id = `Prox_ID`,
    # fire_history_type = `Type`,
    # water_station_id = `WaterStation_ID`,
) |> 
  mutate(
    fire_start = ymd(fire_start),
    fire_contained = ymd(fire_contained)
  ) 
```

### Water Quality

```{r}
water_quality_raw = read_tsv(paste(RAW_DATA_FILE_PATH, "analytes.tsv", sep = ''))

water_quality = water_quality_raw |> rename(
  station_code = `StationCode`, # required for analysis
  collection_depth = `CollectionDepth`,  
  unit_collection_depth = `UnitCollectionDepth`, 
  analyte = `Analyte`,             # required for analysis
  unit = `Unit`,           # required for analysis
  result = `Result`,        
  latitude = `latitude`,           
  longitude = `longitude`,   
  position_water_column = `PositionWaterColumn`,
  huc12_name = `Huc12_name`,  
  huc12_number = `Huc12_number`,  
  sample_date = `SampleDate`, # required for analysis
  collection_time = `CollectionTime` # required for analysis
  ) |>  
  mutate(sample_date_time = mdy_hms(sample_date))

hour(water_quality$sample_date_time) = hour(mdy_hms(water_quality$collection_time))
minute(water_quality$sample_date_time) = minute(mdy_hms(water_quality$collection_time))
second(water_quality$sample_date_time) = second(mdy_hms(water_quality$collection_time))

water_quality = water_quality |> 
  select(-c(sample_date, collection_time))

```

### CRAM Sites / CRAM Measurements

These are stored in a single table

```{r}
cram_measurements_raw = readxl::read_excel(paste(RAW_DATA_FILE_PATH, "FinalizedCramSites-2-26-24.xlsx", sep = '')) 

cram_measurements = cram_measurements_raw |> 
  rename(
    ecram_id                = `ecramid`,
    visit_date              = `visitdate`,
    fire_history_type       = `Fire/Control`,
    time_relative_to_fire   = `Pre/Post_Fire`,
    group_id                = `Group_ID`,
    pair_id                 = `Pair_ID`,
    index_score             = `indexscore`,
    buffer_lan              = `bufferlan`,
    hydrology               = `hydrology`,
    physical                = `physical`,
    biotic_str              = `biotic_str`,
    year                    = `YEAR_`,
    fire_name               = `FIRE_NAME`,
    alarm_date              = `ALARM_DATE`,
    cont_date               = `CONT_DATE`,
    us_l4code               = `US_L4CODE`,
    us_l4name               = `US_L4NAME`,
    nearest_fire            = `NearestFire`,
    near_fid                = `NEAR_FID`,
    site_id                 = `SITE_ID`,
    prox_id                 = `PROX_ID`,
    shape_length            = `SHAPE_Length`,
    shape_area              = `SHAPE_Area`,
    mountain_range          = `MountainRange`,
    time_interval_elevation = `TimeInterval/Elevtation`,
  ) |> 

  # format date
  mutate(
    visit_date = ymd(visit_date),
    alarm_date = ymd(alarm_date),
    cont_date = ymd(cont_date)
    
  ) 
```

## Clean Data

1.  Get only WQ data for applicable Water Stations

```{r}
water_quality = water_quality |> 
  filter(station_code %in% water_stations$station_code) |> 
  filter(analyte != "Nitrogen, Inorganic, Total")
```

2.  Get selected analytes names

```{r}
analytes_of_interest = water_quality$analyte |> unique()
```

2.  Set target date for water station measurements

    nearest to the target date

```{r}
assert(
  water_stations |> filter(is.na(fire_name)) |> nrow() == 0,
  msg = 'All Water Stations should have an associated fire'
  )


start_date = min(water_quality$sample_date_time)
end_date = max(water_quality$sample_date_time)

  
create_date_dataframe = function(date_interval, start_date, end_date) {
  day_interval = interval(start_date,end_date)/date_interval
  dates = start_date + 0:day_interval*date_interval
  next_date = dates + date_interval

  
  date_df = as.data.frame(dates) |> 
    rename(date = dates) |> 
    mutate(date = as.Date(date),
           next_date = as.Date(next_date)) |> 
    mutate(date_interval = interval(date, next_date)) 
  
  print(date_df)
}

dates = create_date_dataframe(dmonths(1), start_date, end_date)

station_codes = water_stations |> select(c(station_code)) |> 
  unique()

water_station_observations = tidyr::crossing(station_codes, dates)

water_station_observations
```

```{r}

map_date_to_most_recent_fire = function(water_station_observations, water_stations) {
  most_recent_fire = inner_join(
    water_station_observations,
    water_stations,
    by = join_by(
      station_code,
      closest(date >= fire_start)
    )
  ) |> rename(
    previous_fire_start = fire_start,
    previous_fire_name = fire_name,
    previous_fire_contained = fire_contained
  )
  
  next_fire = inner_join(
    water_station_observations, 
    water_stations,
    by = join_by(
      station_code,
      closest(date < fire_start)
    )
  ) |> rename(
    next_fire_start = fire_start,
    next_fire_name = fire_name,
    next_fire_contained = fire_contained
  ) |> select(c(
    station_code,
    date,
    next_fire_start,
    next_fire_name,
    next_fire_contained
  ))
  
  inner_join(
    most_recent_fire,
    next_fire,
    by = join_by(
      station_code,
      date
    )
  )
}

map = map_date_to_most_recent_fire(water_station_observations = water_station_observations |> filter(station_code == "11-331" | station_code == "405BRCAMS"), water_stations)
```

```{r}

filter(water_station_observations, dates %in% water_stations$fire_start)


class(water_stations$fire_start)
class(as.Date(water_quality$sample_date_time))







#####

water_station_observations = water_stations |>
  pivot_longer(
    cols = c(fire_start, fire_contained),
    names_to = "fire_date_type",
    values_to = "fire_date"
  ) |> 
  mutate(
    target_date_type = case_when(
      fire_date_type == 'fire_start' ~ "pre",
      fire_date_type == 'fire_contained' ~ "post",
    )
  ) |> 
  # determining target date in separate mutation in case this changes
  mutate(
    target_date = case_when(
      target_date_type == "pre" ~ as.Date(fire_date - target_date_distance),
      target_date_type == "post" ~ as.Date(fire_date + target_date_distance)
    )
  )
```

3.  Normalize analytes

```{r}

## clean up units per analyte 

analytes = water_quality |> 
  select(c(analyte, unit)) |>
  group_by(analyte) |> 
  reframe(
    unit = unique(unit)
  ) 

duplicate_analytes = analytes |> 
  group_by(analyte) |> 
  filter(n() > 1)

assert(
  duplicate_analytes |> nrow() == 0,
  msg = "Analytes should not have more than one unit"
)

analytes
```

4.  Determine fire and target date for water quality data

```{r}

assert(
  water_stations$station_code |> length() == water_stations$station_code |> unique() |> length(),
  msg = "water stations should have unique codes"
)

assert(
  water_station_observations$station_code |> length() == water_stations$station_code |> length() * 2,
  msg = "there should be twice as many observations as stations"
)

assert(
  water_quality |> filter(
  !(water_quality$station_code %in% water_stations$station_code)
) |> nrow() == 0 &
water_stations |> filter(
  !(water_stations$station_code %in% water_quality$station_code)
) |> nrow() == 0
, msg = "There should be no station codes that are only in one set"
)

TARGET_DATE_BUFFER = dyears(5)

valid_water_quality = water_station_observations |> 
  left_join(
    water_quality |> 
      select(-c(latitude, longitude)), 
    by = join_by(station_code), 
    relationship = "many-to-many"
  ) |> 
  filter(
    fire_date_type == "fire_start" & sample_date_time < fire_date |
    fire_date_type == "fire_contained" & sample_date_time > fire_date) |> 
  mutate(
    distance_from_target_date = abs(sample_date_time - as_datetime(target_date))
  ) |> 
  filter(distance_from_target_date < TARGET_DATE_BUFFER) |> 
  group_by(station_code, target_date_type, analyte) |>
  filter(
    distance_from_target_date == min(distance_from_target_date)
  )

 # sometimes there are multiple readings for the same time, date, and analyte
 # sometimes there different readings at surface vs subsurface
 valid_water_quality |>
       select(colnames(water_quality)) |> 
  filter(n() > 1) |> 
  arrange(.by_group = T)

 # assert there is one per group
 assert(
   valid_water_quality |>
   filter(n() > 1) |> nrow() == 0,
   msg = "There should be one analyte per group"
 )
  
# for now just take the mean and investigate later
 mean_water_quality = valid_water_quality |> 
   reframe(
     result = mean(result)
   )
 
 # need to bring back the unit (fix this assertion)
 assert(
   mean_water_quality$unit |> unique() |> length() > 0
 )
 
 # strategy for analytes 
 STRATEGY = "post-only"
 if (STRATEGY == "pre-post-pairs") {
    valid_stations_with_analytes = mean_water_quality |> 
       group_by(station_code, analyte) |> 
       reframe(
         timeframes = unique(target_date_type) |> length()
       ) |> 
       filter(timeframes > 1) |> 
       select(station_code, analyte)
              
    optimized_water_quality = left_join(valid_stations_with_analytes, mean_water_quality, by = join_by(station_code, analyte))
        
    assert(
        filter(
          optimized_water_quality,
          target_date_type == "pre"
        ) |> 
        nrow() == filter(
          optimized_water_quality,
          target_date_type == "post"
        ) |> nrow(),
      msg = "Should have same number pre and post"
    )
 } else if (STRATEGY == "post-only") {
   valid_stations_with_analytes = mean_water_quality |> 
     filter(target_date_type == "post") |> 
     select(station_code, analyte, target_date_type)
   
    optimized_water_quality = left_join(valid_stations_with_analytes, mean_water_quality, by = join_by(station_code, analyte, target_date_type))
    
    assert(
      optimized_water_quality |> 
        filter(
          target_date_type == "pre"
        ) |> 
        nrow() == 0,
      msg = "Should exclude pre"
    )
 }  

 
 assert(
   (sum(is.na(optimized_water_quality))) == 0,
   msg = "Should be no NAs"
 )
 
 assert(
   sum(is.na( 
     (optimized_water_quality |> 
        pivot_wider(
          id_cols = c(station_code, analyte),
          names_from = target_date_type,
          values_from = result
        ))
     )) == 0,
    msg = "There should be no missing results"
 )

```

## Select Analytes

```{r}
ANALYTE_SELECTION_STRATEGY = "of-interest"
```

```{r}
if (ANALYTE_SELECTION_STRATEGY == "of-interest") {
  analytes_of_interest = c("Total Dissolved Solids, Dissolved",
                         "Total Organic Carbon, Total",
                         "Phosphorus as P, Total", 
                         "Oxygen, Dissolved, Total",
                         "Nitrogen, Total, Total"  
                         )
  
  optimized_water_quality |> filter(analyte %in% analytes_of_interest)
} 
```

```{r}
if(ANALYTE_SELECTION_STRATEGY == "reduce" & F) {
  final_set = select_analytes_and_replicates_by_reduce(
    optimized_water_quality = optimized_water_quality
    )
} else {
  final_set =  list("analytes" = c("Total Dissolved Solids, Dissolved",
                         "Total Organic Carbon, Total",
                         "Phosphorus as P, Total", 
                         "Oxygen, Dissolved, Total",
                         "Nitrogen, Total, Total"  
                         ),
                    "replicates" = optimized_water_quality |> filter(analyte %in% analytes_of_interest) |> group_by(station_code)
                    |> select(station_code) |> unique()
  )
}
```

### 

```{r}
  # analytes_count_matrix should be all 1s
  final_analytes = final_set$analytes
  final_station_replicates = final_set$replicates
  
  filtered_water_quality = filter_water_quality_by_analyte_and_replicate(
    analytes = final_analytes,
    replicates = final_station_replicates,
    id_cols = c('station_code'),
    water_quality = optimized_water_quality
  )
  
  analytes_results_matrix = create_analyte_matrix_with_results(
    water_quality_for_replicates = filtered_water_quality,
    id_cols = c("station_code")
  )
  
assert(
  sum(is.na((analytes_results_matrix))) == 0,
  msg = "there should be no NAs in the results matrix"
)
```

## PCA

```{r}
library(vegan)
library(factoextra)


# Way to do it so you can get eigenvalues/goodness of fit
results_distance <- vegdist(analytes_results_matrix, method = "euclidean")

results_pca = prcomp(results_distance, scale = TRUE)

fviz_eig(results_pca)

fviz_pca_ind(results_pca)

fviz_pca_ind(
  results_pca, 
  axes = c(1, 2), # change which PCA axes you're viewing here
             
  col.ind = "cos2", # Color by the quality of representation
             
  gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             
  repel = TRUE     # Avoid text overlapping
)
```

Jazzmyn

-   units and

-   Viewing the analyte data in a better way

    -   

1.  NMDS - environment variables, incorporate time
2.  Time replicates of stations HOW
